{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d43ab30-98bc-463d-b206-4697c6f2bb7e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "import matplotlib.dates as mdates\n",
    "import pandas as pd\n",
    "import pandas_datareader.data as web\n",
    "import yfinance as yf\n",
    "from pandas_datareader import data as pdr\n",
    "#import cufflinks as cf\n",
    "#from plotly.offline import iplot, init_notebook_mode\n",
    "#import chart_studio.plotly as py\n",
    "#import mplfinance as mpf\n",
    "#from mplfinance.original_flavor import candlestick_ohlc\n",
    "\n",
    "import requests\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import display\n",
    "#import pandas as pd\n",
    "import numpy as np\n",
    "#from tqdm.notebook import tqdm\n",
    "from datetime import datetime, timedelta, timezone\n",
    "import re\n",
    "import json\n",
    "from typing import List, Dict, Tuple, Optional, Union, Any, Set\n",
    "from datetime import datetime\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import pickle\n",
    "import requests\n",
    "import os\n",
    "\n",
    "style.use('ggplot')\n",
    "\n",
    "# 1) Using pandas datareader and Yahoo Finance\n",
    "yf.pdr_override()\n",
    "\n",
    "df = pdr.get_data_yahoo('AMZN', start = '2019-03-01', end='2024-03-10', progress=False)\n",
    "df.to_csv('amzn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9eaa878b-ad0f-4828-8bf3-287cec404ff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MMM', 'AOS', 'ABT', 'ABBV', 'ACN', 'ADBE', 'AMD', 'AES', 'AFL', 'A', 'APD', 'ABNB', 'AKAM', 'ALB', 'ARE', 'ALGN', 'ALLE', 'LNT', 'ALL', 'GOOGL', 'GOOG', 'MO', 'AMZN', 'AMCR', 'AEE', 'AAL', 'AEP', 'AXP', 'AIG', 'AMT', 'AWK', 'AMP', 'AME', 'AMGN', 'APH', 'ADI', 'ANSS', 'AON', 'APA', 'AAPL', 'AMAT', 'APTV', 'ACGL', 'ADM', 'ANET', 'AJG', 'AIZ', 'T', 'ATO', 'ADSK', 'ADP', 'AZO', 'AVB', 'AVY', 'AXON', 'BKR', 'BALL', 'BAC', 'BK', 'BBWI', 'BAX', 'BDX', 'BRK.B', 'BBY', 'BIO', 'TECH', 'BIIB', 'BLK', 'BX', 'BA', 'BKNG', 'BWA', 'BXP', 'BSX', 'BMY', 'AVGO', 'BR', 'BRO', 'BF.B', 'BLDR', 'BG', 'CDNS', 'CZR', 'CPT', 'CPB', 'COF', 'CAH', 'KMX', 'CCL', 'CARR', 'CTLT', 'CAT', 'CBOE', 'CBRE', 'CDW', 'CE', 'COR', 'CNC', 'CNP', 'CF', 'CHRW', 'CRL', 'SCHW', 'CHTR', 'CVX', 'CMG', 'CB', 'CHD', 'CI', 'CINF', 'CTAS', 'CSCO', 'C', 'CFG', 'CLX', 'CME', 'CMS', 'KO', 'CTSH', 'CL', 'CMCSA', 'CMA', 'CAG', 'COP', 'ED', 'STZ', 'CEG', 'COO', 'CPRT', 'GLW', 'CTVA', 'CSGP', 'COST', 'CTRA', 'CCI', 'CSX', 'CMI', 'CVS', 'DHR', 'DRI', 'DVA', 'DAY', 'DE', 'DAL', 'XRAY', 'DVN', 'DXCM', 'FANG', 'DLR', 'DFS', 'DG', 'DLTR', 'D', 'DPZ', 'DOV', 'DOW', 'DHI', 'DTE', 'DUK', 'DD', 'EMN', 'ETN', 'EBAY', 'ECL', 'EIX', 'EW', 'EA', 'ELV', 'LLY', 'EMR', 'ENPH', 'ETR', 'EOG', 'EPAM', 'EQT', 'EFX', 'EQIX', 'EQR', 'ESS', 'EL', 'ETSY', 'EG', 'EVRG', 'ES', 'EXC', 'EXPE', 'EXPD', 'EXR', 'XOM', 'FFIV', 'FDS', 'FICO', 'FAST', 'FRT', 'FDX', 'FIS', 'FITB', 'FSLR', 'FE', 'FI', 'FLT', 'FMC', 'F', 'FTNT', 'FTV', 'FOXA', 'FOX', 'BEN', 'FCX', 'GRMN', 'IT', 'GEHC', 'GEN', 'GNRC', 'GD', 'GE', 'GIS', 'GM', 'GPC', 'GILD', 'GPN', 'GL', 'GS', 'HAL', 'HIG', 'HAS', 'HCA', 'DOC', 'HSIC', 'HSY', 'HES', 'HPE', 'HLT', 'HOLX', 'HD', 'HON', 'HRL', 'HST', 'HWM', 'HPQ', 'HUBB', 'HUM', 'HBAN', 'HII', 'IBM', 'IEX', 'IDXX', 'ITW', 'ILMN', 'INCY', 'IR', 'PODD', 'INTC', 'ICE', 'IFF', 'IP', 'IPG', 'INTU', 'ISRG', 'IVZ', 'INVH', 'IQV', 'IRM', 'JBHT', 'JBL', 'JKHY', 'J', 'JNJ', 'JCI', 'JPM', 'JNPR', 'K', 'KVUE', 'KDP', 'KEY', 'KEYS', 'KMB', 'KIM', 'KMI', 'KLAC', 'KHC', 'KR', 'LHX', 'LH', 'LRCX', 'LW', 'LVS', 'LDOS', 'LEN', 'LIN', 'LYV', 'LKQ', 'LMT', 'L', 'LOW', 'LULU', 'LYB', 'MTB', 'MRO', 'MPC', 'MKTX', 'MAR', 'MMC', 'MLM', 'MAS', 'MA', 'MTCH', 'MKC', 'MCD', 'MCK', 'MDT', 'MRK', 'META', 'MET', 'MTD', 'MGM', 'MCHP', 'MU', 'MSFT', 'MAA', 'MRNA', 'MHK', 'MOH', 'TAP', 'MDLZ', 'MPWR', 'MNST', 'MCO', 'MS', 'MOS', 'MSI', 'MSCI', 'NDAQ', 'NTAP', 'NFLX', 'NEM', 'NWSA', 'NWS', 'NEE', 'NKE', 'NI', 'NDSN', 'NSC', 'NTRS', 'NOC', 'NCLH', 'NRG', 'NUE', 'NVDA', 'NVR', 'NXPI', 'ORLY', 'OXY', 'ODFL', 'OMC', 'ON', 'OKE', 'ORCL', 'OTIS', 'PCAR', 'PKG', 'PANW', 'PARA', 'PH', 'PAYX', 'PAYC', 'PYPL', 'PNR', 'PEP', 'PFE', 'PCG', 'PM', 'PSX', 'PNW', 'PXD', 'PNC', 'POOL', 'PPG', 'PPL', 'PFG', 'PG', 'PGR', 'PLD', 'PRU', 'PEG', 'PTC', 'PSA', 'PHM', 'QRVO', 'PWR', 'QCOM', 'DGX', 'RL', 'RJF', 'RTX', 'O', 'REG', 'REGN', 'RF', 'RSG', 'RMD', 'RVTY', 'RHI', 'ROK', 'ROL', 'ROP', 'ROST', 'RCL', 'SPGI', 'CRM', 'SBAC', 'SLB', 'STX', 'SRE', 'NOW', 'SHW', 'SPG', 'SWKS', 'SJM', 'SNA', 'SO', 'LUV', 'SWK', 'SBUX', 'STT', 'STLD', 'STE', 'SYK', 'SYF', 'SNPS', 'SYY', 'TMUS', 'TROW', 'TTWO', 'TPR', 'TRGP', 'TGT', 'TEL', 'TDY', 'TFX', 'TER', 'TSLA', 'TXN', 'TXT', 'TMO', 'TJX', 'TSCO', 'TT', 'TDG', 'TRV', 'TRMB', 'TFC', 'TYL', 'TSN', 'USB', 'UBER', 'UDR', 'ULTA', 'UNP', 'UAL', 'UPS', 'URI', 'UNH', 'UHS', 'VLO', 'VTR', 'VLTO', 'VRSN', 'VRSK', 'VZ', 'VRTX', 'VFC', 'VTRS', 'VICI', 'V', 'VMC', 'WRB', 'WAB', 'WBA', 'WMT', 'DIS', 'WBD', 'WM', 'WAT', 'WEC', 'WFC', 'WELL', 'WST', 'WDC', 'WRK', 'WY', 'WHR', 'WMB', 'WTW', 'GWW', 'WYNN', 'XEL', 'XYL', 'YUM', 'ZBRA', 'ZBH', 'ZION', 'ZTS']\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "url = \"https://en.wikipedia.org/wiki/List_of_S%26P_500_companies\"\n",
    "resp = requests.get(url)\n",
    "soup = BeautifulSoup(resp.content, 'html.parser')\n",
    "\n",
    "table = soup.find('table', {'class':'wikitable sortable'})\n",
    "tickers = []\n",
    "for row in table.findAll('tr')[1:]:\n",
    "  ticker = row.findAll('td')[0].text\n",
    "  ticker = ticker.strip()                #to drop '\\n' character \n",
    "  tickers.append(ticker)\n",
    "\n",
    "with open(\"sp500tickers.pickle\",\"wb\") as f:\n",
    "        pickle.dump(tickers,f)\n",
    "\n",
    "print(tickers)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c05eef9-8da9-4d5f-96de-62a8dd79004b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_sp500_tickers():\n",
    "    resp = requests.get('http://en.wikipedia.org/wiki/List_of_S%26P_500_companies')\n",
    "    soup = BeautifulSoup(resp.content, 'html.parser')\n",
    "    table = soup.find('table', {'class': 'wikitable sortable'})\n",
    "    tickers = []\n",
    "    for row in table.findAll('tr')[1:]:\n",
    "        ticker = row.findAll('td')[0].text\n",
    "        ticker = ticker.strip()\n",
    "        tickers.append(ticker)\n",
    "    with open(\"sp500tickers.pickle\", \"wb\") as f:\n",
    "        pickle.dump(tickers, f)\n",
    "    #print(tickers)\n",
    "    return tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736ea690-6e2c-43eb-8b59-1dff02040a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save_sp500_tickers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8a991d1e-c6ad-424c-adee-6057c9b56067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already have MMM\n",
      "Already have AOS\n",
      "Already have ABT\n",
      "Already have ABBV\n",
      "Already have ACN\n",
      "Already have ADBE\n",
      "Already have AMD\n",
      "Already have AES\n",
      "Already have AFL\n",
      "Already have A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1 Failed download:\n",
      "['BRK.B']: Exception('%ticker%: No timezone found, symbol may be delisted')\n",
      "\n",
      "1 Failed download:\n",
      "['BF.B']: Exception('%ticker%: No price data found, symbol may be delisted (1d 2018-01-01 00:00:00 -> 2024-03-13 21:43:14.815695)')\n"
     ]
    }
   ],
   "source": [
    "def get_data_from_yahoo(reload_sp500=False):\n",
    "    if reload_sp500:\n",
    "        tickers = save_sp500_tickers()\n",
    "    else:\n",
    "        with open(\"sp500tickers.pickle\", \"rb\") as f:\n",
    "            tickers = pickle.load(f)\n",
    "    if not os.path.exists('stock_dfs'):\n",
    "        os.makedirs('stock_dfs')\n",
    "\n",
    "    start = dt.datetime(2018, 1, 1)      #start date\n",
    "    end = dt.datetime.now()              #End date which is current\n",
    "    for ticker in tickers:\n",
    "        # just in case your connection breaks, we'd like to save our progress!\n",
    "        if not os.path.exists('stock_dfs/{}.csv'.format(ticker)):\n",
    "            df = pdr.get_data_yahoo(ticker, start = start, end= end, progress=False)\n",
    "            #df = web.DataReader(ticker, 'yahoo', start, end)\n",
    "            #df.reset_index(inplace=True)\n",
    "            #df.set_index(\"Date\", inplace=True)\n",
    "            #df = df.drop(\"Symbol\", axis=1)\n",
    "            df.to_csv('stock_dfs/{}.csv'.format(ticker))\n",
    "        else:\n",
    "            print('Already have {}'.format(ticker))\n",
    "\n",
    "\n",
    "get_data_from_yahoo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af5915b9-11a3-4000-a0dc-43b77255bfc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "2\n",
      "4\n",
      "6\n",
      "8\n",
      "10\n",
      "12\n",
      "14\n",
      "16\n",
      "18\n",
      "20\n",
      "22\n",
      "24\n",
      "26\n",
      "28\n",
      "30\n",
      "32\n",
      "34\n",
      "36\n",
      "38\n",
      "40\n",
      "42\n",
      "44\n",
      "46\n",
      "48\n",
      "50\n",
      "52\n",
      "54\n",
      "56\n",
      "58\n",
      "60\n",
      "62\n",
      "64\n",
      "66\n",
      "68\n",
      "70\n",
      "72\n",
      "74\n",
      "76\n",
      "78\n",
      "80\n",
      "82\n",
      "84\n",
      "86\n",
      "88\n",
      "90\n",
      "92\n",
      "94\n",
      "96\n",
      "98\n",
      "100\n",
      "102\n",
      "104\n",
      "106\n",
      "108\n",
      "110\n",
      "112\n",
      "114\n",
      "116\n",
      "118\n",
      "120\n",
      "122\n",
      "124\n",
      "126\n",
      "128\n",
      "130\n",
      "132\n",
      "134\n",
      "136\n",
      "138\n",
      "140\n",
      "142\n",
      "144\n",
      "146\n",
      "148\n",
      "150\n",
      "152\n",
      "154\n",
      "156\n",
      "158\n",
      "160\n",
      "162\n",
      "164\n",
      "166\n",
      "168\n",
      "170\n",
      "172\n",
      "174\n",
      "176\n",
      "178\n",
      "180\n",
      "182\n",
      "184\n",
      "186\n",
      "188\n",
      "190\n",
      "192\n",
      "194\n",
      "196\n",
      "198\n",
      "200\n",
      "202\n",
      "204\n",
      "206\n",
      "208\n",
      "210\n",
      "212\n",
      "214\n",
      "216\n",
      "218\n",
      "220\n",
      "222\n",
      "224\n",
      "226\n",
      "228\n",
      "230\n",
      "232\n",
      "234\n",
      "236\n",
      "238\n",
      "240\n",
      "242\n",
      "244\n",
      "246\n",
      "248\n",
      "250\n",
      "252\n",
      "254\n",
      "256\n",
      "258\n",
      "260\n",
      "262\n",
      "264\n",
      "266\n",
      "268\n",
      "270\n",
      "272\n",
      "274\n",
      "276\n",
      "278\n",
      "280\n",
      "282\n",
      "284\n",
      "286\n",
      "288\n",
      "290\n",
      "292\n",
      "294\n",
      "296\n",
      "298\n",
      "300\n",
      "302\n",
      "304\n",
      "306\n",
      "308\n",
      "310\n",
      "312\n",
      "314\n",
      "316\n",
      "318\n",
      "320\n",
      "322\n",
      "324\n",
      "326\n",
      "328\n",
      "330\n",
      "332\n",
      "334\n",
      "336\n",
      "338\n",
      "340\n",
      "342\n",
      "344\n",
      "346\n",
      "348\n",
      "350\n",
      "352\n",
      "354\n",
      "356\n",
      "358\n",
      "360\n",
      "362\n",
      "364\n",
      "366\n",
      "368\n",
      "370\n",
      "372\n",
      "374\n",
      "376\n",
      "378\n",
      "380\n",
      "382\n",
      "384\n",
      "386\n",
      "388\n",
      "390\n",
      "392\n",
      "394\n",
      "396\n",
      "398\n",
      "400\n",
      "402\n",
      "404\n",
      "406\n",
      "408\n",
      "410\n",
      "412\n",
      "414\n",
      "416\n",
      "418\n",
      "420\n",
      "422\n",
      "424\n",
      "426\n",
      "428\n",
      "430\n",
      "432\n",
      "434\n",
      "436\n",
      "438\n",
      "440\n",
      "442\n",
      "444\n",
      "446\n",
      "448\n",
      "450\n",
      "452\n",
      "454\n",
      "456\n",
      "458\n",
      "460\n",
      "462\n",
      "464\n",
      "466\n",
      "468\n",
      "470\n",
      "472\n",
      "474\n",
      "476\n",
      "478\n",
      "480\n",
      "482\n",
      "484\n",
      "486\n",
      "488\n",
      "490\n",
      "492\n",
      "494\n",
      "496\n",
      "498\n",
      "500\n",
      "502\n",
      "                  MMM        AOS         ABT        ABBV         ACN  \\\n",
      "Date                                                                   \n",
      "2024-03-07  92.620003  86.650002  120.919998  180.570007  386.910004   \n",
      "2024-03-08  93.900002  85.820000  120.959999  178.850006  378.170013   \n",
      "2024-03-11  94.050003  85.309998  120.190002  179.630005  373.220001   \n",
      "2024-03-12        NaN        NaN         NaN         NaN         NaN   \n",
      "2024-03-13        NaN        NaN         NaN         NaN         NaN   \n",
      "\n",
      "                  ADBE         AMD        AES        AFL           A  ...  \\\n",
      "Date                                                                  ...   \n",
      "2024-03-07  556.039978  211.380005  16.160000  82.290001  149.309998  ...   \n",
      "2024-03-08  551.690002  207.389999  16.250000  82.110001  147.869995  ...   \n",
      "2024-03-11  560.419983  198.389999  16.389999  83.169998  147.289993  ...   \n",
      "2024-03-12         NaN         NaN        NaN        NaN         NaN  ...   \n",
      "2024-03-13         NaN         NaN        NaN        NaN         NaN  ...   \n",
      "\n",
      "                   WTW         GWW        WYNN        XEL         XYL  \\\n",
      "Date                                                                    \n",
      "2024-03-07  274.359985  989.039978  101.110001  50.040001  126.970001   \n",
      "2024-03-08  273.709991  970.320007  100.430000  51.020000  127.080002   \n",
      "2024-03-11  271.970001  963.989990  103.230003  52.910000  126.180000   \n",
      "2024-03-12  274.980011  972.429993  103.040001  51.900002  128.460007   \n",
      "2024-03-13  274.899994  974.739990  102.330002  51.500000  128.020004   \n",
      "\n",
      "                   YUM        ZBRA         ZBH       ZION         ZTS  \n",
      "Date                                                                   \n",
      "2024-03-07  140.380005  288.589996  127.360001  41.520000  181.509995  \n",
      "2024-03-08  139.559998  282.589996  126.739998  42.240002  182.160004  \n",
      "2024-03-11  140.080002  280.230011  128.039993  41.610001  183.490005  \n",
      "2024-03-12  140.740005  285.440002  128.210007  40.900002  181.350006  \n",
      "2024-03-13  138.360001  284.500000  126.589996  41.070000  176.229996  \n",
      "\n",
      "[5 rows x 503 columns]\n"
     ]
    }
   ],
   "source": [
    "def compile_data():\n",
    "    with open(\"sp500tickers.pickle\", \"rb\") as f:\n",
    "        tickers = pickle.load(f)\n",
    "\n",
    "    main_df = pd.DataFrame()\n",
    "\n",
    "    for count, ticker in enumerate(tickers):\n",
    "        df = pd.read_csv('stock_dfs/{}.csv'.format(ticker))\n",
    "        df.set_index('Date', inplace=True)\n",
    "\n",
    "        df.rename(columns={'Adj Close': ticker}, inplace=True)\n",
    "        df.drop(['Open', 'High', 'Low', 'Close', 'Volume'], axis=1, inplace=True)\n",
    "\n",
    "        if main_df.empty:\n",
    "            main_df = df\n",
    "        else:\n",
    "            main_df = main_df.join(df, how='outer')      #Joining all the Adjusted Close columns of all the stocks\n",
    "\n",
    "        if count % 2 == 0:\n",
    "            print(count)\n",
    "    print(main_df.tail())\n",
    "    main_df.to_csv('sp500_joined_closes.csv')\n",
    "\n",
    "\n",
    "compile_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2a5694a-f21a-46a5-a91b-4a852b701a0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Date         MMM        AOS        ABT       ABBV         ACN  \\\n",
      "0  1.514851e+09  184.653259  55.089031  52.831726  74.280685  140.376053   \n",
      "1  1.514938e+09  184.645401  55.420311  52.948547  75.443100  141.023865   \n",
      "2  1.515024e+09  187.058945  55.679947  52.858696  75.012840  142.693771   \n",
      "3  1.515110e+09  188.516510  56.396206  53.011467  76.318672  143.870834   \n",
      "4  1.515370e+09  187.905273  56.664799  52.858696  75.095879  145.020538   \n",
      "\n",
      "         ADBE    AMD       AES        AFL  ...         WTW         GWW  \\\n",
      "0  177.699997  10.98  8.897790  37.835312  ...  134.813431  214.155701   \n",
      "1  181.039993  11.55  8.889608  37.947144  ...  137.335617  212.811005   \n",
      "2  183.220001  12.12  8.856895  38.338535  ...  138.729675  214.473633   \n",
      "3  185.339996  11.88  8.889608  38.592281  ...  139.619354  216.463440   \n",
      "4  185.039993  12.28  8.889608  38.691212  ...  138.867325  216.463440   \n",
      "\n",
      "         WYNN        XEL        XYL        YUM        ZBRA         ZBH  \\\n",
      "0  153.166199  40.135132  63.101509  72.933296  103.709999  114.987968   \n",
      "1  151.506790  39.866512  63.870922  72.870720  105.769997  115.785072   \n",
      "2  152.327148  39.555904  64.297340  73.612556  107.860001  115.618248   \n",
      "3  153.343338  39.278877  64.176826  74.041580  109.540001  116.767563   \n",
      "4  151.301712  39.572689  64.408569  74.166718  110.629997  116.990005   \n",
      "\n",
      "        ZION        ZTS  \n",
      "0  41.675041  68.807129  \n",
      "1  41.625713  69.123497  \n",
      "2  41.798332  69.535759  \n",
      "3  41.814777  70.331482  \n",
      "4  41.609276  71.175179  \n",
      "\n",
      "[5 rows x 504 columns]\n",
      "Date    float64\n",
      "MMM     float64\n",
      "AOS     float64\n",
      "ABT     float64\n",
      "ABBV    float64\n",
      "         ...   \n",
      "YUM     float64\n",
      "ZBRA    float64\n",
      "ZBH     float64\n",
      "ZION    float64\n",
      "ZTS     float64\n",
      "Length: 504, dtype: object\n",
      "          Date       MMM       AOS       ABT      ABBV       ACN      ADBE  \\\n",
      "Date  1.000000 -0.741772  0.677033  0.815654  0.904784  0.892611  0.690497   \n",
      "MMM  -0.741772  1.000000 -0.214125 -0.329162 -0.633200 -0.433272 -0.220795   \n",
      "AOS   0.677033 -0.214125  1.000000  0.641276  0.753350  0.823126  0.685984   \n",
      "ABT   0.815654 -0.329162  0.641276  1.000000  0.675365  0.914908  0.845615   \n",
      "ABBV  0.904784 -0.633200  0.753350  0.675365  1.000000  0.825439  0.511587   \n",
      "...        ...       ...       ...       ...       ...       ...       ...   \n",
      "YUM   0.890429 -0.549387  0.733831  0.808294  0.804321  0.889697  0.665498   \n",
      "ZBRA  0.446522  0.156923  0.528498  0.835412  0.326934  0.709710  0.766030   \n",
      "ZBH   0.220291  0.166945  0.252616  0.520862  0.060029  0.347654  0.496786   \n",
      "ZION  0.073542  0.383970  0.385386  0.329490  0.240504  0.368552  0.186093   \n",
      "ZTS   0.843454 -0.391172  0.706615  0.956666  0.704210  0.950852  0.896844   \n",
      "\n",
      "           AMD       AES       AFL  ...       WTW       GWW      WYNN  \\\n",
      "Date  0.861501  0.690689  0.848798  ...  0.873721  0.911338 -0.603916   \n",
      "MMM  -0.468004 -0.226180 -0.657310  ... -0.492913 -0.712215  0.528802   \n",
      "AOS   0.781133  0.469739  0.730173  ...  0.668006  0.785610 -0.054985   \n",
      "ABT   0.891301  0.830933  0.554771  ...  0.886226  0.624855 -0.582226   \n",
      "ABBV  0.762073  0.602198  0.860662  ...  0.751689  0.906439 -0.436483   \n",
      "...        ...       ...       ...  ...       ...       ...       ...   \n",
      "YUM   0.810052  0.733123  0.869507  ...  0.866776  0.835448 -0.403916   \n",
      "ZBRA  0.657056  0.743243  0.206676  ...  0.635324  0.240596 -0.310059   \n",
      "ZBH   0.347307  0.553590  0.085103  ...  0.503248  0.128642  0.097492   \n",
      "ZION  0.211125  0.436045  0.186928  ...  0.214175  0.028122  0.036713   \n",
      "ZTS   0.929430  0.736387  0.611597  ...  0.868983  0.684334 -0.566330   \n",
      "\n",
      "           XEL       XYL       YUM      ZBRA       ZBH      ZION       ZTS  \n",
      "Date  0.777402  0.735696  0.890429  0.446522  0.220291  0.073542  0.843454  \n",
      "MMM  -0.479552 -0.212125 -0.549387  0.156923  0.166945  0.383970 -0.391172  \n",
      "AOS   0.345733  0.789714  0.733831  0.528498  0.252616  0.385386  0.706615  \n",
      "ABT   0.853373  0.819900  0.808294  0.835412  0.520862  0.329490  0.956666  \n",
      "ABBV  0.603962  0.649494  0.804321  0.326934  0.060029  0.240504  0.704210  \n",
      "...        ...       ...       ...       ...       ...       ...       ...  \n",
      "YUM   0.717762  0.839653  1.000000  0.544931  0.365461  0.227445  0.835197  \n",
      "ZBRA  0.612312  0.738920  0.544931  1.000000  0.613104  0.547565  0.794455  \n",
      "ZBH   0.432527  0.544308  0.365461  0.613104  1.000000  0.110047  0.453817  \n",
      "ZION  0.136277  0.347248  0.227445  0.547565  0.110047  1.000000  0.287451  \n",
      "ZTS   0.817639  0.827397  0.835197  0.794455  0.453817  0.287451  1.000000  \n",
      "\n",
      "[504 rows x 504 columns]\n"
     ]
    }
   ],
   "source": [
    "def visualize_data():\n",
    "    df = pd.read_csv('sp500_joined_closes.csv')\n",
    "    # Convert the 'Date' column to datetime objects\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    # Convert the 'Date' column to Unix timestamps\n",
    "    df['Date'] = df['Date'].apply(lambda x: x.timestamp())\n",
    "\n",
    "    # Convert the 'Date' column to float\n",
    "    df['Date'] = df['Date'].astype(float)\n",
    "\n",
    "    # Print the DataFrame\n",
    "    print(df.head())\n",
    "    \n",
    "    #df = df.reset_index()\n",
    "    #df['Date'] = df['Date'].map(mdates.date2num)\n",
    "    print(df.dtypes)\n",
    "    print(df.corr())\n",
    "   # df['ABBV'].plot()\n",
    "   # plt.show()\n",
    "visualize_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61551021-e714-4e91-8d77-302fb6bfaf90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data_for_labels(ticker):\n",
    "    hm_days = 7\n",
    "    df = pd.read_csv('sp500_joined_closes.csv', index_col=0)\n",
    "    tickers = df.columns.values.tolist()\n",
    "    df.fillna(0, inplace=True)\n",
    "\n",
    "    for i in range(1,hm_days+1):\n",
    "        df['{}_{}d'.format(ticker,i)] = (df[ticker].shift(-i) - df[ticker]) / df[ticker]\n",
    "\n",
    "    df.fillna(0, inplace=True)\n",
    "    return tickers, df\n",
    "\n",
    "#process_data_for_labels('AMD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "97b636ab-2f81-426b-8210-777e48f54b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def buy_sell_hold(*args):\n",
    "    cols = [c for c in args]\n",
    "    requirement = 0.02   #stock price changes by 2% we have to take notice with in 7 days\n",
    "    for col in cols:\n",
    "        if col > requirement:\n",
    "            return 1\n",
    "        if col < -requirement:\n",
    "            return -1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a693e7a-3cd7-43f9-aa12-fbab7982d6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def extract_featuresets(ticker):\n",
    "    tickers, df = process_data_for_labels(ticker)\n",
    "\n",
    "    df['{}_target'.format(ticker)] = list(map( buy_sell_hold,\n",
    "                                               df['{}_1d'.format(ticker)],\n",
    "                                               df['{}_2d'.format(ticker)],\n",
    "                                               df['{}_3d'.format(ticker)],\n",
    "                                               df['{}_4d'.format(ticker)],\n",
    "                                               df['{}_5d'.format(ticker)],\n",
    "                                               df['{}_6d'.format(ticker)],\n",
    "                                               df['{}_7d'.format(ticker)] ))\n",
    "    vals = df['{}_target'.format(ticker)].values.tolist()\n",
    "    str_vals = [str(i) for i in vals]\n",
    "    print('Data spread:',Counter(str_vals))\n",
    "    df.fillna(0, inplace=True)\n",
    "    df = df.replace([np.inf, -np.inf], np.nan)\n",
    "    df.dropna(inplace=True)\n",
    "    df_vals = df[[ticker for ticker in tickers]].pct_change()    # % chage data for all of the companies - X_train\n",
    "    df_vals = df_vals.replace([np.inf, -np.inf], 0)\n",
    "    df_vals.fillna(0, inplace=True)\n",
    "    X = df_vals.values                                    #Feature sets\n",
    "    y = df['{}_target'.format(ticker)].values             #Lables  - Target classification\n",
    "    return X,y,df\n",
    "\n",
    "\n",
    "#extract_featuresets('XOM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6dba93b2-7177-4470-926e-eee2b43e9590",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn as scikit_learn\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4fdde251-9793-4ae7-88eb-02dd9ca24e52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data spread: Counter({'1': 734, '-1': 596, '0': 229})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\16475\\anaconda3\\envs\\Foundations_Data_Science\\Lib\\site-packages\\sklearn\\svm\\_classes.py:31: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.49902912621359224\n",
      "Predicted class counts: Counter({1: 331, -1: 182, 0: 2})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.49902912621359224"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def do_ml(ticker):\n",
    "    # Extract features and labels\n",
    "    X, y, df = extract_featuresets(ticker)\n",
    "\n",
    "    # Check if any of the returned values are None or empty\n",
    "    if any(elem is None or (isinstance(elem, np.ndarray) and elem.size == 0) or (isinstance(elem, pd.DataFrame) and elem.empty) for elem in (X, y, df)):\n",
    "        print(\"Error: extract_featuresets returned None or empty\")\n",
    "        return None\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "    # Initialize the classifiers for the voting ensemble\n",
    "    classifiers = [('LinearSVC', LinearSVC()), \n",
    "                   ('KNeighbors', KNeighborsClassifier()), \n",
    "                   ('RandomForest', RandomForestClassifier())]\n",
    "\n",
    "    # Create the voting classifier\n",
    "    clf = VotingClassifier(classifiers)\n",
    "\n",
    "    # Train the model\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate the model\n",
    "    accuracy = clf.score(X_test, y_test)\n",
    "    print('Accuracy:', accuracy)\n",
    "\n",
    "    # Make predictions\n",
    "    predictions = clf.predict(X_test)\n",
    "    print('Predicted class counts:', Counter(predictions))\n",
    "\n",
    "    return accuracy\n",
    "# examples of running:\n",
    "do_ml('XOM')\n",
    "#do_ml('AAPL')\n",
    "#do_ml('ABT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b128aed-c736-4cc3-9f34-5996a562c72e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
